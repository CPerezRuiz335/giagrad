{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08f0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "from giagrad import Tensor\n",
    "import giagrad.nn as nn\n",
    "import giagrad.optim as optim \n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3469127",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(url, type_data = None):\n",
    "    # Extract the dataset from the compressed file\n",
    "    with gzip.open(urllib.request.urlopen(url)) as f:\n",
    "        if type_data == 'label':\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        else:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)\n",
    "    return data\n",
    "\n",
    "X_train_all = fetch(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")\n",
    "Y_train_all = fetch(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", 'label')\n",
    "X_test_all = fetch(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")\n",
    "Y_test_all = fetch(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\", 'label')\n",
    "\n",
    "print(X_train_all.shape)\n",
    "print(X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6bc6b",
   "metadata": {},
   "source": [
    "### Resize and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bba953",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 3000\n",
    "n_test = 500\n",
    "\n",
    "# Every row is a flattened image\n",
    "X_train = X_train_all[:n_train].reshape(-1, 28*28)\n",
    "Y_train = Y_train_all[:n_train]\n",
    "\n",
    "X_test = X_test_all[:n_test].reshape(-1, 28*28)\n",
    "Y_test = Y_test_all[:n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55af135",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims: List[int]):\n",
    "        self.layers = [nn.Linear(in_, out) for in_, out in pairwise(dims)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.layers[0](x)\n",
    "        for layer in self.layers[1:]:\n",
    "            x = x.relu()\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return sum([l.parameters() for l in self.layers], [])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"MLP\\n\\t\" + '\\n\\t'.join(str(layer) for layer in self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP([784, 600, 10])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe1ef4b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d213a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=0.01, \n",
    "    momentum=0.,\n",
    "    nesterov=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for ite in (prog_bar := trange(40)):\n",
    "     # Zero gradient \n",
    "    optimizer.zero_grad() \n",
    "    # Pass data through the network\n",
    "    output = model(X_train)\n",
    "    # Calculate loss\n",
    "    loss = criterion(output, Y_train)\n",
    "    # Backpropagate\n",
    "    loss.backward(debug=True)\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    prog_bar.set_description(f\"It: {ite}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf632fe",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = [model(pred).softmax(axis=1).data.argmax() == y \n",
    "             for pred, y in zip(X_train, Y_train)]\n",
    "\n",
    "print(f'train accuracy: {sum(hits)/n_train*100} %')\n",
    "\n",
    "hits = [model(pred).softmax(axis=1).data.argmax() == y \n",
    "             for pred, y in zip(X_test, Y_test)]\n",
    "\n",
    "print(f'test accuracy: {sum(hits)/n_test*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
