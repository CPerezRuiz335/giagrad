:py:mod:`giagrad`
=================

.. py:module:: giagrad


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   display/index.rst
   nn/index.rst
   optim/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   initializers/index.rst
   mathops/index.rst
   mlops/index.rst
   reductionops/index.rst
   shapeops/index.rst
   tensor/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   giagrad.Tensor
   giagrad.Module
   giagrad.CrossEntropyLoss
   giagrad.Linear
   giagrad.Dropout
   giagrad.Dropout1d
   giagrad.Dropout2d
   giagrad.Dropout3d



Functions
~~~~~~~~~

.. autoapisummary::

   giagrad.calculate_gain



.. py:class:: Tensor(data, requires_grad: bool = False, context: Optional[Context] = None, name: str = '', dtype=np.float32)

   .. py:property:: shape
      :type: Tuple[int, Ellipsis]


   .. py:property:: dtype
      :type: type


   .. py:property:: size
      :type: int


   .. py:property:: ndim
      :type: int


   .. py:property:: T


   .. py:attribute:: __array_ufunc__

      Attributes
      ----------
      data: np.ndarray
          weights
      grad: NDArray
          gradients
      requires_grad: bool
          indicates if automatic differentiation is needed
      name: Optional[str]
          variable name, for visualization
      _ctx: Context
          class Context: defines parent nodes and function that created it
              like _prev and _op in micrograd.


   .. py:attribute:: __slots__
      :value: ['data', 'grad', '_ctx', 'requires_grad', 'name']

      

   .. py:method:: backward(debug: bool = False)

      https://github.com/karpathy/micrograd/blob/master/micrograd/engine.py
      a.k.a topological sort / postorder then reversed


   .. py:method:: no_grad() -> Tensor


   .. py:method:: requires_grad_() -> Tensor


   .. py:method:: __repr__()

      Return repr(self).


   .. py:method:: __str__()

      Return str(self).


   .. py:method:: empty(*shape, **kwargs) -> Tensor
      :classmethod:


   .. py:method:: zeros()


   .. py:method:: ones()


   .. py:method:: constant(val)


   .. py:method:: normal(mu, sigma)


   .. py:method:: uniform(a, b)


   .. py:method:: dirac(groups=1)


   .. py:method:: xavier_uniform(gain=1)


   .. py:method:: xavier_normal(gain=1)


   .. py:method:: kaiming_uniform(neg_slope=0, mode='fan_in', nonlinearity='leaky_relu')


   .. py:method:: kaiming_normal(neg_slope=0, mode='fan_in', nonlinearity='leaky_relu')


   .. py:method:: sparse(sparsity, std=0.01)


   .. py:method:: orthogonal(gain=1)


   .. py:method:: comm(operator: Context, *tensors, **kwargs) -> Tensor
      :classmethod:


   .. py:method:: sqrt()


   .. py:method:: square()


   .. py:method:: exp()


   .. py:method:: log()


   .. py:method:: reciprocal()


   .. py:method:: abs()


   .. py:method:: __neg__()


   .. py:method:: clip(min_, max_)
      :abstractmethod:


   .. py:method:: sign()
      :abstractmethod:


   .. py:method:: relu()


   .. py:method:: sigmoid()


   .. py:method:: elu(alpha=1.0)


   .. py:method:: silu(beta=1.0)


   .. py:method:: tanh()


   .. py:method:: leakyrelu(neg_slope=0.01)


   .. py:method:: softplus(limit=20, beta=1)


   .. py:method:: quick_gelu()


   .. py:method:: gelu()


   .. py:method:: relu6()


   .. py:method:: mish()


   .. py:method:: hardswish()


   .. py:method:: softmax(axis: int)


   .. py:method:: log_softmax(axis: int)


   .. py:method:: __add__(x)


   .. py:method:: __radd__(x)


   .. py:method:: __sub__(x)


   .. py:method:: __rsub__(x)


   .. py:method:: __mul__(x)


   .. py:method:: __rmul__(x)


   .. py:method:: __pow__(x)


   .. py:method:: __rpow__(x)


   .. py:method:: __matmul__(x)


   .. py:method:: __rmatmul__(x)


   .. py:method:: __truediv__(x)


   .. py:method:: __rtruediv__(x)


   .. py:method:: __iadd__(x)


   .. py:method:: __isub__(x)


   .. py:method:: __imul__(x)


   .. py:method:: __ipow__(x)


   .. py:method:: __itruediv__(x)


   .. py:method:: __imatmul__(x)


   .. py:method:: mean(axis: Union[Tuple[int, Ellipsis], int, None] = None, keepdims: bool = False)


   .. py:method:: sum(axis: Union[Tuple[int, Ellipsis], int, None] = None, keepdims: bool = False)


   .. py:method:: max(axis: Union[Tuple[int, Ellipsis], int, None] = None, keepdims: bool = False)


   .. py:method:: min(axis: Union[Tuple[int, Ellipsis], int, None] = None, keepdims: bool = False)


   .. py:method:: add(x)


   .. py:method:: sub(x)


   .. py:method:: mul(x)


   .. py:method:: pow(x)


   .. py:method:: matmul(x)


   .. py:method:: div(x)


   .. py:method:: permute(axes=None)


   .. py:method:: transpose(dim0, dim1)



.. py:class:: Module

   Bases: :py:obj:`abc.ABC`

   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:method:: __setattr__(key, value)

      Implement setattr(self, name, value).


   .. py:method:: train()


   .. py:method:: eval()


   .. py:method:: apply(fn: Callable)


   .. py:method:: parameters() -> List[giagrad.tensor.Tensor]


   .. py:method:: zero_grad()


   .. py:method:: __repr__()

      Return repr(self).


   .. py:method:: __str__()

      Return str(self).


   .. py:method:: __call__(x) -> giagrad.tensor.Tensor
      :abstractmethod:



.. py:class:: CrossEntropyLoss(reduction: str = 'mean')

   .. py:method:: __call__(weights: giagrad.tensor.Tensor, y_true: Union[giagrad.tensor.Tensor, numpy.typing.NDArray], axis: int = 1, mean_axis: int = 0) -> giagrad.tensor.Tensor



.. py:class:: Linear(in_features: int, out_features: int, bias: bool = True)

   Bases: :py:obj:`giagrad.nn.module.Module`

   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:method:: __call__(x: giagrad.tensor.Tensor) -> giagrad.tensor.Tensor


   .. py:method:: __str__()

      Return str(self).



.. py:class:: Dropout(p: float = 0.5)

   Bases: :py:obj:`giagrad.nn.module.Module`

   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:method:: __call__(x: giagrad.tensor.Tensor) -> giagrad.tensor.Tensor


   .. py:method:: __str__()

      Return str(self).



.. py:class:: Dropout1d(p: float = 0.5)

   Bases: :py:obj:`DropoutNd`

   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:method:: __check(ndim: int)



.. py:class:: Dropout2d(p: float)

   Bases: :py:obj:`DropoutNd`

   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:method:: __check(ndim: int)



.. py:class:: Dropout3d(p: float)

   Bases: :py:obj:`DropoutNd`

   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:method:: __check(ndim: int)



.. py:function:: calculate_gain(nonlinearity, neg_slope=None)


