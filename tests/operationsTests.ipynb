{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62753ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7caddfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff21f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c44dd",
   "metadata": {},
   "source": [
    "# Binary operators\n",
    "## Dot product\n",
    "\n",
    "Parece que todo es \n",
    "\n",
    "```python\n",
    "a_grad = c_grad @ b.T \n",
    "b_grad = a.T @ c_grad\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dd732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def backprop_torch(a, b, const=1):\n",
    "    a = torch.tensor(a, requires_grad=True)\n",
    "    b = torch.tensor(b, requires_grad=True)\n",
    "    c = a @ b\n",
    "    c.retain_grad()\n",
    "    (c.sum() * const).backward()\n",
    "    \n",
    "    print('a_grad_torch:\\n', a.grad.detach().numpy(), end='\\n'*2)\n",
    "    print('b_grad_torch:\\n', b.grad.detach().numpy(), end='\\n'*2)\n",
    "    print('c_grad_torch:\\n', c.grad.detach().numpy(), end='\\n'*2)\n",
    "\n",
    "def backprop(a, b, const=1):\n",
    "    c = a @ b\n",
    "    c_grad = np.ones_like(c)*const\n",
    "    \n",
    "    a_grad = c_grad @ b.T \n",
    "    b_grad = a.T @ c_grad\n",
    "    \n",
    "    print('a_grad:\\n', a_grad, end='\\n'*2)\n",
    "    print('b_grad:\\n', b_grad, end='\\n'*2)\n",
    "    print('c_grad:\\n', c_grad, end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7127e56",
   "metadata": {},
   "source": [
    "### Scalar matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae6f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_grad_torch:\n",
      " [[13.2]]\n",
      "\n",
      "b_grad_torch:\n",
      " [[6.6 6.6 6.6 6.6]]\n",
      "\n",
      "c_grad_torch:\n",
      " [[3.3 3.3 3.3 3.3]]\n",
      "\n",
      "a_grad:\n",
      " [[13.2]]\n",
      "\n",
      "b_grad:\n",
      " [[6.6 6.6 6.6 6.6]]\n",
      "\n",
      "c_grad:\n",
      " [[3.3 3.3 3.3 3.3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[2.]])\n",
    "b = np.array([[1.,1., 1., 1.]])\n",
    "\n",
    "backprop_torch(a, b, 3.3)\n",
    "backprop(a, b, 3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4cead",
   "metadata": {},
   "source": [
    "### Matrix vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9be9d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_grad_torch:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "b_grad_torch:\n",
      " [[4.]\n",
      " [4.]]\n",
      "\n",
      "c_grad_torch:\n",
      " [[1.]\n",
      " [1.]]\n",
      "\n",
      "a_grad:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "b_grad:\n",
      " [[4.]\n",
      " [4.]]\n",
      "\n",
      "c_grad:\n",
      " [[1.]\n",
      " [1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[2.,2.],\n",
    "              [2.,2.]])\n",
    "b = np.array([[1.,1.]]).T\n",
    "\n",
    "backprop_torch(a, b)\n",
    "backprop(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3821461",
   "metadata": {},
   "source": [
    "### Vector matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14826fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_grad_torch:\n",
      " [[4. 4.]]\n",
      "\n",
      "b_grad_torch:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "c_grad_torch:\n",
      " [[1. 1.]]\n",
      "\n",
      "a_grad:\n",
      " [[4. 4.]]\n",
      "\n",
      "b_grad:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "c_grad:\n",
      " [[1. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backprop_torch(b.T, a)\n",
    "backprop(b.T, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ecd9f",
   "metadata": {},
   "source": [
    "### Matrix Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bad190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_grad_torch:\n",
      " [[4. 4.]\n",
      " [4. 4.]]\n",
      "\n",
      "b_grad_torch:\n",
      " [[4. 4.]\n",
      " [4. 4.]]\n",
      "\n",
      "c_grad_torch:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "a_grad:\n",
      " [[4. 4.]\n",
      " [4. 4.]]\n",
      "\n",
      "b_grad:\n",
      " [[4. 4.]\n",
      " [4. 4.]]\n",
      "\n",
      "c_grad:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backprop_torch(a, a)\n",
    "backprop(a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9439a",
   "metadata": {},
   "source": [
    "## Hadamard product\n",
    "\n",
    "Como multiplicacion de escalares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2713c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[4.,5.],\n",
    "              [1.,3.],\n",
    "              [9.,0.]])\n",
    "\n",
    "b = np.array([[2.,2.],\n",
    "              [2.,2.],\n",
    "              [2.,2.]])\n",
    "\n",
    "a_tensor = torch.tensor(a, requires_grad=True)\n",
    "b_tensor = torch.tensor(b, requires_grad=True)\n",
    "c_tensor = a_tensor * b_tensor\n",
    "c_tensor.retain_grad()\n",
    "c_tensor.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d37438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_grad_tensor:\n",
      " tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]], dtype=torch.float64)\n",
      "\n",
      "b_grad_tensor:\n",
      " tensor([[4., 5.],\n",
      "        [1., 3.],\n",
      "        [9., 0.]], dtype=torch.float64)\n",
      "\n",
      "c_grad_tensor:\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('a_grad_tensor:\\n', a_tensor.grad, end='\\n'*2)\n",
    "print('b_grad_tensor:\\n', b_tensor.grad, end='\\n'*2)\n",
    "print('c_grad_tensor:\\n', c_tensor.grad, end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f853c1",
   "metadata": {},
   "source": [
    "## Add\n",
    "\n",
    "Parece que vuelve a ser Hadamard product, cosa que makes sense.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial sum}{\\partial a} = \\frac{\\partial sum}{\\partial sum}  \n",
    "                                  \\frac{\\partial sum}{\\partial c} \n",
    "                                  \\frac{\\partial c}{\\partial a}\\\\\n",
    "\\frac{\\partial sum}{\\partial a} = 1\n",
    "                                  \\frac{\\partial sum}{\\partial c} \n",
    "                                  \\frac{\\partial c}{\\partial a}\\\\\n",
    "\\frac{\\partial c_{1,1}}{\\partial a_{1,1}} = a_{1,1} + b_{1,1} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70242afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[4.,5.],\n",
    "              [1.,3.],\n",
    "              [9.,0.]])\n",
    "\n",
    "b = np.array([[2.,2.],\n",
    "              [2.,2.],\n",
    "              [2.,2.]])\n",
    "\n",
    "a_tensor = torch.tensor(a, requires_grad=True)\n",
    "b_tensor = torch.tensor(b, requires_grad=True)\n",
    "c_tensor = a_tensor + b_tensor\n",
    "c_tensor.retain_grad()\n",
    "(c_tensor.sum()*3).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94dd9e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_grad_tensor:\n",
      " tensor([[3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.]], dtype=torch.float64)\n",
      "\n",
      "b_grad_tensor:\n",
      " tensor([[3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.]], dtype=torch.float64)\n",
      "\n",
      "c_grad_tensor:\n",
      " tensor([[3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.]], dtype=torch.float64)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  7.],\n",
       "        [ 3.,  5.],\n",
       "        [11.,  2.]], dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('a_grad_tensor:\\n', a_tensor.grad, end='\\n'*2)\n",
    "print('b_grad_tensor:\\n', b_tensor.grad, end='\\n'*2)\n",
    "print('c_grad_tensor:\\n', c_tensor.grad, end='\\n'*2)\n",
    "c_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047a93e",
   "metadata": {},
   "source": [
    "# Reduction operators\n",
    "\n",
    "## Sum\n",
    "\n",
    "Derivative of the sum of any Tensor is just zeros_like(tensor), but wat happens\n",
    "when it's combined with scalar multiplication on another Tensor of different size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65099955",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[2.,2.],\n",
    "              [2.,2.],\n",
    "              [3.,3.]])\n",
    "\n",
    "b = np.array([[1.,2.],\n",
    "              [3.,4.],\n",
    "              [5.,6.]])\n",
    "\n",
    "a_tensor = torch.tensor(a, requires_grad=True)\n",
    "c_tensor = torch.tensor(b, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af8ee092",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tensor = a_tensor.sum()\n",
    "b_tensor.retain_grad()\n",
    "\n",
    "d_tensor = (b_tensor * c_tensor).sum()\n",
    "d_tensor.retain_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab119a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39e79410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21., dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24d39e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_tensor.sum() == b_tensor.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d79e923",
   "metadata": {},
   "source": [
    "## Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "804702dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tensor = torch.tensor(a, requires_grad=True)\n",
    "c_tensor = torch.tensor(b, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f0a624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tensor = a_tensor.max()\n",
    "d_tensor = b_tensor * c_tensor\n",
    "d_tensor.retain_grad()\n",
    "d_tensor.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6110e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [10.5000, 10.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "748cf45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., dtype=torch.float64, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd609539",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f08cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tensor = torch.tensor(a, requires_grad=True)\n",
    "c_tensor = torch.tensor(b, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c98abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tensor = a_tensor.mean()\n",
    "b_tensor.retain_grad()\n",
    "d_tensor = b_tensor * c_tensor\n",
    "d_tensor.retain_grad()\n",
    "d_tensor.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2f5234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000],\n",
       "        [1.0000, 1.0000],\n",
       "        [1.0000, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb11eeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3333, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a80365",
   "metadata": {},
   "source": [
    "## Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "484717a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a_tensor.log()\n",
    "b.requires_grad_()\n",
    "b.retain_grad()\n",
    "c = b.exp()\n",
    "c.requires_grad_()\n",
    "c.retain_grad()\n",
    "d = c.sum()\n",
    "d.retain_grad()\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a288dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000],\n",
       "        [1.0000, 1.0000],\n",
       "        [1.0000, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d590124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [3., 3.]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929cd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc79853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa721d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [1., 3.],\n",
       "        [9., 0.]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "072c277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tensor = torch.Tensor([1.]).double().requires_grad_()\n",
    "b_tensor.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3e43cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b_tensor.exp()\n",
    "c.retain_grad()\n",
    "\n",
    "d = c * a_tensor\n",
    "d.retain_grad()\n",
    "\n",
    "d.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eee94ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(1.).shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a4c5666",
   "metadata": {},
   "source": [
    "a_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f6048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
